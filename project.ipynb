{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import mtcnn\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import keras\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,Activation,Input\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(input_shape,labels):\n",
    "    model=Sequential()\n",
    "    \n",
    "    model.add(Conv2D(64,(3,3),padding=\"valid\",activation=\"relu\",input_shape=input_shape))\n",
    "    model.add(Conv2D(64,(3,3),padding=\"valid\",activation=\"relu\",input_shape=input_shape))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(128,(3,3),padding=\"valid\",activation=\"relu\"))\n",
    "    model.add(Conv2D(128,(3,3),padding=\"valid\",activation=\"relu\"))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128,activation=\"relu\"))\n",
    "    model.add(Dense(64,activation=\"relu\"))\n",
    "    model.add(Dense(len(labels)))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    \n",
    "    model.summary()\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def Crete_Folder_Images(name, directory, tn):\n",
    "    # Creating directory in the file\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    else:\n",
    "        print('DIRECTORY with name %s EXIST'%name)\n",
    "    # Opening vedio mode with frontal face detector\n",
    "    detector=mtcnn.MTCNN()\n",
    "    cam=cv2.VideoCapture(0)\n",
    "    size =(100, 100)\n",
    "    for i in tqdm(range(1, 1+ tn)):\n",
    "        ret,img=cam.read()\n",
    "        faces=detector.detect_faces(img)\n",
    "        for face in faces:\n",
    "            bounding_box = face['box']\n",
    "            x=bounding_box[0]\n",
    "            y=bounding_box[1]\n",
    "            w=bounding_box[2]\n",
    "            h=bounding_box[3]\n",
    "            x1,y1=abs(x),abs(y)\n",
    "            x2,y2=x1+w,y1+h\n",
    "            face=img[y1:y2,x1:x2]\n",
    "            image=Image.fromarray(face)\n",
    "            image=image.resize(size)\n",
    "            face_array=np.asarray(image)\n",
    "            cv2.imwrite('images/'+str(name)+'/'+str(name)+'_'+str(i)+'.jpg', face_array)  #for GRAY SCALE IMAGES\n",
    "\n",
    "            # cv2.imwrite(directory+'/'+str(name)+'-'+str(sn)+'.jpg'\n",
    "            #             ,img[y:y+h,x:x+w])  # FOR COLOR IMAGES\n",
    "            cv2.putText(img,str(i),(25,25),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "            cv2.imshow('Sample Collector',img)\n",
    "            cv2.waitKey(200)\n",
    "            \n",
    "    \n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print('TASK COMPLETED')\n",
    "\n",
    "\n",
    "def print_progress(val,val_len,folder,bar_size=20):\n",
    "    prog=\"#\"*round((val)*bar_size/val_len)+\" \"*round((val_len-(val))*bar_size/val_len)\n",
    "    if val==0:\n",
    "        print(\"\",end=\"\\n\")\n",
    "    else:\n",
    "        print(\"[%s] (%d samples)\\t label : %s \\t\\t\" % (prog,val+1,folder), end=\"\\r\")\n",
    "        \n",
    "def register():\n",
    "    import mysql.connector  \n",
    "    name=input(\"Enter name:\")\n",
    "    i=float(input(\"Enter id:\"))\n",
    "    g=input(\"M or F\")\n",
    "    ph=int(input(\"Enter Phone Number\"))\n",
    "    ''''mydb = mysql.connector.connect(host = \"localhost\", user = \"root\",passwd = \"Vyshnav@2002\",database='fras')  \n",
    "    mycursor = mydb.cursor()\n",
    "\n",
    "    sql = \"INSERT INTO student VALUES (%s,%s, %s,%s)\"\n",
    "    val = (name,i,ph,g)\n",
    "    mycursor.execute(sql, val)\n",
    "\n",
    "    mydb.commit()'''\n",
    "    \n",
    "    dir='images/'+name  \n",
    "    #Crete_Folder_Images(name,dir,5)\n",
    "    \n",
    "    dir='download/'\n",
    "    names=[]\n",
    "    images=[]\n",
    "    for folder in os.listdir(dir):\n",
    "        files=os.listdir(os.path.join(dir,folder))\n",
    "        for i,name in enumerate(files):\n",
    "            img=cv2.imread(os.path.join(dir+folder,name))\n",
    "            cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "            images.append(img)\n",
    "            names.append(folder)\n",
    "            print_progress(i,len(files),folder)\n",
    "    time.sleep(5)\n",
    "    print(\"no:of samples :\",len(names))\n",
    "    le=LabelEncoder()\n",
    "    le.fit(names)\n",
    "    labels=le.classes_\n",
    "    name_vec=le.transform(names)\n",
    "    categorical_name_vec=to_categorical(name_vec)\n",
    "\n",
    "    x_train,x_test,y_train,y_test=train_test_split(np.array(images,dtype=np.float32),np.array(categorical_name_vec),test_size=0.15,random_state=42)\n",
    "\n",
    "    input_shape=x_train[0].shape\n",
    "    EPOCHS=50\n",
    "    BATCH_SIZE=32\n",
    "\n",
    "    model=cnn_model(input_shape,labels)\n",
    "    history=model.fit(x_train,y_train,epochs=EPOCHS,batch_size=BATCH_SIZE,shuffle=True,validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter name:rr\n",
      "Enter id:3\n",
      "M or Fr\n",
      "Enter Phone Number44\n",
      "\n",
      "[####################] (312 samples)\t label : Dhoni \t\t\n",
      "[####################] (491 samples)\t label : Messi \t\t\n",
      "[####################] (415 samples)\t label : Ronaldo \t\t\n",
      "no:of samples : 1660#] (442 samples)\t label : Virat \t\t\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_32 (Conv2D)          (None, 98, 98, 64)        1792      \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 96, 96, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 48, 48, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 46, 46, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 44, 44, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 22, 22, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 61952)             0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 128)               7929984   \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 4)                 260       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 4)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,198,660\n",
      "Trainable params: 8,198,660\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "38/38 [==============================] - 104s 3s/step - loss: 10.7062 - accuracy: 0.3745 - val_loss: 1.3314 - val_accuracy: 0.4340\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 93s 2s/step - loss: 0.9835 - accuracy: 0.6005 - val_loss: 0.9196 - val_accuracy: 0.6509\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 98s 3s/step - loss: 0.6567 - accuracy: 0.7389 - val_loss: 0.8777 - val_accuracy: 0.7028\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 99s 3s/step - loss: 0.4704 - accuracy: 0.8173 - val_loss: 1.0240 - val_accuracy: 0.7075\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 100s 3s/step - loss: 0.2996 - accuracy: 0.8932 - val_loss: 1.0997 - val_accuracy: 0.7217\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 98s 3s/step - loss: 0.2204 - accuracy: 0.9166 - val_loss: 0.9318 - val_accuracy: 0.7358\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 101s 3s/step - loss: 0.1377 - accuracy: 0.9541 - val_loss: 1.2486 - val_accuracy: 0.7594\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 99s 3s/step - loss: 0.0925 - accuracy: 0.9716 - val_loss: 1.0319 - val_accuracy: 0.7925\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 99s 3s/step - loss: 0.1189 - accuracy: 0.9658 - val_loss: 0.8678 - val_accuracy: 0.7736\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 100s 3s/step - loss: 0.0564 - accuracy: 0.9825 - val_loss: 1.1569 - val_accuracy: 0.7925\n"
     ]
    }
   ],
   "source": [
    "register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "12/12 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n"
     ]
    }
   ],
   "source": [
    "import mtcnn\n",
    "size =(100, 100)\n",
    "detector=mtcnn.MTCNN()\n",
    "img=cv2.imread('testing/d.jpg')\n",
    "cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "pixels=np.asarray(img)\n",
    "faces=detector.detect_faces(img)\n",
    "for res in faces:            \n",
    "    bounding_box = res['box']\n",
    "    x=bounding_box[0]\n",
    "    y=bounding_box[1]\n",
    "    w=bounding_box[2]\n",
    "    h=bounding_box[3]\n",
    "    x1,y1=abs(x),abs(y)\n",
    "    x2,y2=x1+w,y1+h\n",
    "    face=pixels[y1:y2,x1:x2]\n",
    "    face_img=cv2.resize(face,(100,100))\n",
    "    face_img=face_img.reshape(1,100,100,3)\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 119ms/step\n",
      "['Vyshnav']\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(face_img)\n",
    "idx=result.argmax(axis=1)\n",
    "label_text=labels[idx]\n",
    "print(label_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17132\\2236471083.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdetector\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmtcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMTCNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'testing/download.jpeg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mfaces\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect_faces\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mface\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfaces\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import mtcnn\n",
    "size =(100, 100)\n",
    "detector=mtcnn.MTCNN()\n",
    "img=cv2.imread('testing/download.jpeg')\n",
    "cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "faces=detector.detect_faces(img)\n",
    "for face in faces:            \n",
    "    x, y, w, h = face['box']\n",
    "    face_cropped = img[y:y+h, x:x+w]\n",
    "    face_img=cv2.resize(face_cropped,(100,100))\n",
    "    face_img=face_img.reshape(1,100,100,3)\n",
    "    result=model.predict(face_img)\n",
    "    idx=result.argmax(axis=1)\n",
    "    label_text=labels[idx]\n",
    "    print(label_text)\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
